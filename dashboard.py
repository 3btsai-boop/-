import streamlit as st
import pandas as pd
import plotly.express as px
import jieba
import jieba.analyse
from datetime import datetime, timedelta
import os
import time
import base64

# --- 0. å…¨åŸŸè¨­å®š ---
st.set_page_config(
    page_title="ç¾©äº«å¤©åœ°è¼¿æƒ…æˆ°æƒ…å®¤ V15",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

# --- CSS ç¾åŒ– (Flexbox å‰›æ€§ä½ˆå±€ - V9.0 æ¶æ§‹ä¿æŒä¸è®Š) ---
st.markdown("""
    <style>
    .block-container {
        padding-top: 3.5rem; 
        padding-bottom: 2rem;
    }
    
    [data-testid="stMetric"] {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    
    .stPlotlyChart {
        background-color: #ffffff;
        border-radius: 8px;
        box-shadow: 0 2px 6px rgba(0,0,0,0.05);
        padding: 10px;
    }
    
    .header-container {
        display: flex;
        flex-direction: row;
        align-items: center;
        justify-content: flex-start;
        gap: 25px;
        margin-bottom: 20px;
        width: 100%;
    }
    
    .logo-img {
        height: 85px;
        width: auto;
        object-fit: contain;
        flex-shrink: 0;
    }
    
    .title-box {
        display: flex;
        flex-direction: column;
        justify-content: center;
    }
    
    .main-title {
        font-size: 2.5rem;
        font-weight: 700;
        margin: 0;
        line-height: 1.2;
        color: #000;
    }
    
    .sub-title {
        font-size: 1rem;
        color: #666;
        margin-top: 5px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 1. æ ¸å¿ƒé‚è¼¯ï¼šæƒ…ç·’è¨ˆåˆ†å¼•æ“ (V15.0 ç«¶å“é»‘åå–®å¼·åŒ–ç‰ˆ) ---
class SentimentEngine:
    def __init__(self):
        # 1. [çµ•å°èªæ„] å‡ºç¾å³å®šèª¿ (å„ªå…ˆç´šæœ€é«˜)
        self.deadly_negative_patterns = [
            "ä¸æœƒå†ä¾†", "ä¸€æ¬¡åº—", "å†ä¹Ÿä¸", "å‹¸é€€", "ä¸æƒ³å†", "çµ•ä¸", 
            "çˆ›æ­»", "çˆ›é€", "æ°£æ­»", "æ‹’çµ•", "é»‘åå–®", "æµªè²»éŒ¢", 
            "æµªè²»æ™‚é–“", "æœ€çˆ›", "çœŸçš„å¾ˆç³Ÿ", "ç„¡æ³•æ¥å—", "æ²’ä¸‹æ¬¡", 
            "ä¸äºˆç½®è©•", "ä¸æ¨", "ä¸å„ª", "ä¸å¦‚å»", "é‚„ä¸å¦‚", "å¯§é¡˜å»", 
            "è¼¸çµ¦", "æ…˜è¼¸", "è¢«å±Œæ‰“", "ç¬‘æ­»", "ç¬‘çˆ›", "å‚»çœ¼", "ç„¡è¨€", "èª‡å¼µ", "æ‚²åŠ‡"
        ]
        
        self.super_positive_patterns = [
            "å¿…å›è¨ª", "ä¸€å®šæœƒå†", "ä¸€å®šå†", "å”¯ä¸€æ¨è–¦", "ç¥åº—", 
            "æœ€æ„›", "è¶…æ„›", "å¾ˆé ‚", "æ²’å°æ‰‹", "ç¬¬ä¸€å", "æ»¿åˆ†",
            "ä¸€å®šæœƒå†å»", "èˆ’æœ", "å¾ˆå¥½é€›", "å¥½é€›", "è¶…å¥½é€›"
        ]

        # 2. [é—œéµå­—æ¬Šé‡] (ç«¶å“æ‰£åˆ†åŠ é‡è‡³ -3)
        self.neg_words = {
            # è¨­æ–½æŠ±æ€¨
            'B4': -2, 'B5': -4, 'B6': -4, 'B7': -5, 
            'åœè»Š': -3, 'å‡ºå£': -3, 'å‹•ç·š': -4, 'å¡è»Š': -4, 'å¡çˆ†': -5,
            'æ’éšŠ': -3, 'ç­‰å¾ˆä¹…': -3, 'å¡ä½': -3, 'è¿·å®®': -4,
            # æƒ…ç·’è©
            'çˆ›': -5, 'å·®': -4, 'å¤±æœ›': -4, 'é›£åƒ': -4, 'é«’': -4, 'å™å¿ƒ': -5,
            'ç›¤å­': -5, 'æ™ºéšœ': -5, 'å»¢': -4, 'æŠµåˆ¶': -5, 'ç«å¤§': -4, 
            'é›·': -5, 'ç³Ÿç³•': -4, 'å¾Œæ‚”': -4, 'ä¸è¡Œ': -3, 'æ™®é€š': -2,
            # ç«¶å“é»‘åå–® (åªè¦æåˆ°å°æ‰‹ï¼Œé€šå¸¸éƒ½æ˜¯åœ¨è²¶ä½ç¾©äº«ï¼Œæ‰£åˆ†åŠ é‡)
            'å·¨è›‹': -3, 'æ¼¢ç¥': -3, 'å¤¢æ™‚ä»£': -3, 'å¥½å¸‚å¤š': -3, 'Costco': -3, 
            'é ç™¾': -3, 'æ–°å…‰': -3, 'ä¸‰è¶Š': -3, 'è‰è¡™é“': -2, 'é«˜éµ': -1
        }
        
        self.pos_words = {
            # æ­£é¢è©å½™ (æ¬Šé‡åŠ é‡ï¼Œä¿è­·å¥½è©•)
            'å¥½åƒ': 5, 'å¯¬æ•': 4, 'å–œæ­¡': 4, 'æ¨è–¦': 5, 'å¿…åƒ': 5,
            'æ¼‚äº®': 3, 'è³ªæ„Ÿ': 3, 'é–‹å¿ƒ': 3, 'æ£’': 4, 'å„ª': 4,
            'è®š': 5, 'æ¨': 3, 'ä¸éŒ¯': 3, 'æ„›': 4, 'å‹': 3, 'è´': 3,
            'å„ªæƒ ': 2, 'æŠ˜æŠµ': 2, 'æ–¹ä¾¿': 3, 'å¤§': 2, 'æ–°': 2, 
            'æ—­é›†': 4, 'é¥—æ³°å¤š': 4, 'å•é¼': 3, 'äº¬ç¿ ': 3
        }
        
        self.negation_words = ['ä¸', 'æ²’', 'ç„¡', 'é', 'åˆ¥', 'ä¸æœƒ', 'ä¸ç”¨', 'ä¸å¤ª']

    def analyze(self, text):
        if not isinstance(text, str): return "ä¸­æ€§"
        text = text.strip()
        
        # 1. çµ•å°å¿«ç¯©
        for pattern in self.deadly_negative_patterns:
            if pattern in text: return "è² é¢"
        for pattern in self.super_positive_patterns:
            if pattern in text: return "æ­£é¢"

        # 2. å‰è™•ç†
        base_score = 0
        if "[æ¨]" in text: base_score += 1
        if "[å™“]" in text: base_score -= 4
        
        clean_text = text.replace("[æ¨]", "").replace("[å™“]", "").replace("[â†’]", "").replace("[æ¨™é¡Œ]", "")
        
        # 3. é—œéµå­—è¨ˆåˆ†
        score = base_score
        words = jieba.lcut(clean_text)
        
        for i, word in enumerate(words):
            word_score = 0
            if word in self.neg_words:
                word_score = self.neg_words[word]
            elif word in self.pos_words:
                word_score = self.pos_words[word]
            if i > 0 and words[i-1] in self.negation_words:
                word_score = -word_score
            score += word_score
        
        # 4. åˆ¤å®šé–€æª»
        if score <= -1: return "è² é¢"
        elif score >= 2: return "æ­£é¢"
        else: return "ä¸­æ€§"

sentiment_engine = SentimentEngine()

# --- 2. æ•¸æ“šè™•ç† ---
def solve_future_date_issue(df):
    now = datetime.now()
    cutoff = now + timedelta(days=1)
    def adjust_date(x):
        try:
            d = pd.to_datetime(x) if isinstance(x, str) else x
            if pd.isnull(d): return d
            if d > cutoff: return d.replace(year=d.year - 1)
            return d
        except: return x
    df['date'] = df['date'].apply(adjust_date)
    return df

@st.cache_data(ttl=60)
def load_data(csv_path="my_data.csv"):
    if not os.path.exists(csv_path):
        return pd.DataFrame(columns=['date', 'source', 'content', 'link', 'sentiment'])
    df = pd.read_csv(csv_path)
    
    # ğŸš¨ã€é—œéµæ“ä½œã€‘å¼·åˆ¶æ¨æ£„ CSV è£¡å¯èƒ½çš„èˆŠæ¨™ç±¤ï¼Œä½¿ç”¨ V15 å¼•æ“é‡ç®—
    if 'sentiment' in df.columns:
        del df['sentiment']
        
    df['date'] = pd.to_datetime(df['date'], errors='coerce')
    df = df.dropna(subset=['date'])
    df = solve_future_date_issue(df)
    
    # ä½¿ç”¨ V15 å¼•æ“é‡æ–°è¨ˆç®—
    df['sentiment'] = df['content'].apply(sentiment_engine.analyze)
    return df

# --- 3. çˆ¬èŸ²æ•´åˆ (å·²ä¿®å¾©ï¼šè§£æ±º NoneType éŒ¯èª¤) ---
def run_spider_pipeline():
    # å®šç¾©æ©Ÿå™¨äººè®Šæ•¸ï¼Œé¿å…æœªåˆå§‹åŒ–éŒ¯èª¤
    bot = None
    with st.spinner('ğŸš€ æ­£åœ¨å•Ÿå‹•çˆ¬èŸ²è¡›æ˜Ÿï¼Œå…¨é€Ÿæ›´æ–°ä¸­...'):
        try:
            # 1. åŒ¯å…¥æ‚¨çš„çˆ¬èŸ²æª”æ¡ˆ (å¿…é ˆæ˜¯ history_spider_final.py)
            import history_spider_final as spider_module
            
            # 2. åˆå§‹åŒ–çˆ¬èŸ²é¡åˆ¥
            bot = spider_module.EskyHistorySpiderV10()
            
            # ğŸš¨ã€é—œéµä¿®æ­£ã€‘å¼·åˆ¶å•Ÿå‹•ç€è¦½å™¨é©…å‹•ç¨‹å¼ (Driver)
            # é€™è¡Œä»£ç¢¼è§£æ±ºäº† 'NoneType' object has no attribute 'get' çš„å•é¡Œ
            bot.driver = bot._init_selenium()
            
            # 3. é–‹å§‹çˆ¬å– (ç€è¦½å™¨è¦–çª—æœƒè·³å‡ºä¾†ï¼Œè«‹å‹¿é—œé–‰)
            # å¦‚æœ Mobile01 é‡åˆ° Cloudflare é©—è­‰ï¼Œè«‹æ‰‹å‹•åœ¨è·³å‡ºçš„è¦–çª—é»æ“Š
            bot.crawl_ptt()
            bot.crawl_mobile01()
            bot.crawl_dcard()
            
            # 4. å–å¾—æ–°è³‡æ–™
            new_data = bot.data_list
            
            # 5. çˆ¬å–å®Œæˆï¼Œé—œé–‰ç€è¦½å™¨é‡‹æ”¾è¨˜æ†¶é«”
            bot.close()
            
            # 6. è³‡æ–™åˆä½µèˆ‡å­˜æª”
            if new_data:
                if os.path.exists("my_data.csv"):
                    old_df = pd.read_csv("my_data.csv")
                    # ç¢ºä¿èˆŠè³‡æ–™æœ‰è¢«è®€å–ï¼Œä¸¦èˆ‡æ–°è³‡æ–™åˆä½µ
                    final_df = pd.concat([old_df, pd.DataFrame(new_data)])
                else:
                    final_df = pd.DataFrame(new_data)
                    
                # ä»¥å…§å®¹å»é‡ (é¿å…é‡è¤‡æ¨æ–‡)
                final_df.drop_duplicates(subset=['content'], keep='last', inplace=True)
                final_df.to_csv("my_data.csv", index=False, encoding='utf-8-sig')
                st.success(f"âœ… æ›´æ–°æˆåŠŸï¼å…±æ”¶é›† {len(new_data)} ç­†æ–°è³‡æ–™ã€‚")
                time.sleep(2)
                st.rerun()
            else:
                st.warning("âš ï¸ çˆ¬èŸ²åŸ·è¡Œå®Œæˆï¼Œä½†æœªç™¼ç¾æ–°è³‡æ–™ã€‚")
                
        except Exception as e:
            # ç™¼ç”ŸéŒ¯èª¤æ™‚ç¢ºä¿ç€è¦½å™¨é—œé–‰
            if bot and bot.driver:
                bot.close()
            st.error(f"æ›´æ–°å¤±æ•—: {str(e)}")

# --- 4. è¼”åŠ©å‡½æ•¸ ---
def get_img_as_base64(file_path):
    with open(file_path, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

# --- 5. åœ–è¡¨ç¹ªè£½ ---

def plot_clean_trend(df, freq_opt, start_dt, end_dt):
    freq_map = {'æ—¥ (Day)': 'D', 'é€± (Week)': 'W', 'æœˆ (Month)': 'M'}
    freq_code = freq_map[freq_opt]
    
    all_dates = pd.date_range(start=start_dt, end=end_dt, freq=freq_code)
    sentiments = ['æ­£é¢', 'è² é¢', 'ä¸­æ€§']
    full_idx = pd.MultiIndex.from_product([all_dates, sentiments], names=['date', 'sentiment'])
    full_df = pd.DataFrame(index=full_idx).reset_index()
    
    raw_trend = df.groupby([pd.Grouper(key='date', freq=freq_code), 'sentiment']).size().reset_index(name='count')
    trend = pd.merge(full_df, raw_trend, on=['date', 'sentiment'], how='left')
    trend['count'] = trend['count'].fillna(0)
    
    colors = {'æ­£é¢': '#00b894', 'è² é¢': '#d63031', 'ä¸­æ€§': '#b2bec3'}
    
    fig = px.line(
        trend, x='date', y='count', color='sentiment',
        color_discrete_map=colors,
        render_mode='svg'
    )
    
    total_points = len(trend)
    mode_setting = "lines" if total_points > 120 else "lines+markers"

    fig.update_traces(
        mode=mode_setting, 
        line_shape="spline", 
        line_width=2.5,
        marker_size=7,
        hovertemplate='%{y} ç¯‡'
    )
    
    delta_days = (end_dt - start_dt).days
    tick_fmt = "%Y-%m" if delta_days > 365 else "%Y-%m-%d"

    fig.update_layout(
        title="",
        paper_bgcolor='white',
        plot_bgcolor='white',
        hovermode="x unified",
        legend=dict(
            orientation="h", 
            yanchor="bottom", 
            y=1.02, 
            xanchor="left", 
            x=0, 
            title=""
        ),
        xaxis=dict(
            title="",
            showgrid=False,
            range=[start_dt, end_dt],
            tickformat=tick_fmt,
            nticks=12,
            tickangle=0,
            linecolor='#dfe6e9'
        ),
        yaxis=dict(
            title="è²é‡ (ç¯‡)",
            showgrid=True,
            gridcolor='#f1f2f6',
            zeroline=False
        ),
        margin=dict(l=10, r=10, t=30, b=10)
    )
    return fig

def plot_clean_bar(df_kw, color):
    fig = px.bar(
        df_kw, x='æ¬Šé‡', y='é—œéµè©', orientation='h',
        text='æ¬Šé‡'
    )
    fig.update_traces(
        marker_color=color,
        texttemplate='%{text:.1f}', 
        textposition='outside',
        width=0.65
    )
    fig.update_layout(
        plot_bgcolor='white',
        xaxis=dict(visible=False),
        yaxis=dict(categoryorder='total ascending', title=""),
        margin=dict(l=0, r=40, t=30, b=0),
        height=320,
        font=dict(size=14)
    )
    return fig

# --- 6. ä¸»ç¨‹å¼ ---

with st.sidebar:
    st.header("âš™ï¸ ç›£æ¸¬æ§åˆ¶å°")
    if st.button("ğŸš€ å•Ÿå‹•å³æ™‚æ›´æ–°", type="primary"):
        run_spider_pipeline()
    st.markdown("---")
    
    df = load_data()
    if df.empty:
        st.warning("âš ï¸ æš«ç„¡æ•¸æ“š")
        st.stop()
        
    min_date = df['date'].min().date()
    max_date = df['date'].max().date()
    
    target_start = datetime(2021, 1, 1).date()
    default_start = target_start if min_date <= target_start else min_date
    
    st.caption("ğŸ“… æ—¥æœŸç¯©é¸")
    date_range = st.date_input("", [default_start, max_date])

if isinstance(date_range, tuple) and len(date_range) == 2:
    start_dt, end_dt = date_range
    mask = (df['date'].dt.date >= start_dt) & (df['date'].dt.date <= end_dt)
    df_filtered = df.loc[mask]
else:
    st.info("è«‹é¸æ“‡å®Œæ•´çš„æ—¥æœŸèµ·è¨–ã€‚")
    st.stop()

if df_filtered.empty:
    st.warning("æ­¤å€é–“ç„¡æ•¸æ“š")
    st.stop()

# --- Header Area (V9.0 Flexbox æ¶æ§‹) ---

img_tag = ""
if os.path.exists("logo.png"):
    img_b64 = get_img_as_base64("logo.png")
    img_tag = f'<img src="data:image/png;base64,{img_b64}" class="logo-img">'
else:
    img_tag = '<img src="https://www.esky-land.com.tw/img/logo.png" class="logo-img">'

st.markdown(f"""
    <div class="header-container">
        {img_tag}
        <div class="title-box">
            <h1 class="main-title">ç¾©äº«å¤©åœ°ãƒ»è¼¿æƒ…æˆ°æƒ…å®¤</h1>
            <div class="sub-title">Data Range: <b>{start_dt}</b> ~ <b>{end_dt}</b></div>
        </div>
    </div>
""", unsafe_allow_html=True)

st.markdown("---")

# KPI
neg_df = df_filtered[df_filtered['sentiment'] == 'è² é¢']
pos_df = df_filtered[df_filtered['sentiment'] == 'æ­£é¢']
k1, k2, k3, k4 = st.columns(4)
k1.metric("ğŸ“¦ ç¸½è²é‡", f"{len(df_filtered)}")
k2.metric("ğŸ˜¡ è² è©•æ•¸", f"{len(neg_df)}", delta_color="inverse")
k3.metric("ğŸ¥° å¥½è©•æ•¸", f"{len(pos_df)}")
k4.metric("ğŸ“Š è² è©•ç‡", f"{(len(neg_df)/len(df_filtered)*100):.1f}%")

st.markdown("<br>", unsafe_allow_html=True)

# Tabs
t1, t2 = st.tabs(["ğŸ“Š è¶¨å‹¢åˆ†æ", "âš”ï¸ é—œéµå­—å°æ±º"])

with t1:
    day_diff = (end_dt - start_dt).days
    idx = 0
    if day_diff > 365: idx = 2 
    elif day_diff > 60: idx = 1 
    
    col_opt, _ = st.columns([2, 5])
    with col_opt:
        freq_opt = st.radio("æª¢è¦–ç²’åº¦:", ['æ—¥ (Day)', 'é€± (Week)', 'æœˆ (Month)'], index=idx, horizontal=True)

    fig_trend = plot_clean_trend(df_filtered, freq_opt, start_dt, end_dt)
    st.plotly_chart(fig_trend, use_container_width=True)
    
    with st.expander("æŸ¥çœ‹ä¾†æºåˆ†ä½ˆ"):
        fig_pie = px.pie(df_filtered, names='source', hole=0.6, color_discrete_sequence=px.colors.qualitative.Set3)
        st.plotly_chart(fig_pie, use_container_width=True)

with t2:
    c_neg, c_pos = st.columns(2)
    
    # ğŸš¨ã€é—œéµä¿®æ­£ã€‘åœç”¨è©å¤§æ¸…æ´—ï¼šæ¿¾é™¤ã€Œé€™ç¨®ã€ã€ã€Œé‚£å€‹ã€ã€ã€Œæ¯”è¼ƒã€ç­‰ç„¡æ„ç¾©è©
    stop_words = set([
        "é«˜é›„", "ç¾©äº«", "å¤©åœ°", "ç™¾è²¨", "å·¨è›‹", "æ„Ÿè¦º", "æ¯”è¼ƒ", "çœŸçš„", "ç¾åœ¨", "ä»Šå¤©", "æ™‚å€™", "çŸ¥é“", "çœ‹åˆ°", 
        "æœ‰çš„", "æ²’æœ‰", "ä»€éº¼", "å¯ä»¥", "ä¸€å€‹", "å°±æ˜¯", "é‚„æ˜¯", "æˆ‘å€‘", "ä½ å€‘", "å› ç‚º", "å¯èƒ½", "å…¶å¯¦", "è¦ºå¾—", 
        "ä¸é", "é€™å€‹", "é‚£å€‹", "å»é", "å¤§å®¶", "è«‹å•", "å•é¡Œ", "é–’èŠ", "æ–°è", "åˆ†äº«", "æ–‡ç« ", "ä½œè€…", "æ¨™é¡Œ", 
        "æ™‚é–“", "åŸæœ¬", "ä»¥ç‚º", "çµæœ", "éƒ¨åˆ†", "ç›®å‰", "å·²ç¶“", "æ€éº¼", "é€™æ¨£", "æœ€è¿‘", "é€™å®¶", "é€™ç¨®", "é‚£ç¨®",
        "ä¸€æ¨£", "ä¸€é»", "ä¸€ä¸‹", "ä¸€ç›´", "åªæ˜¯", "ä½†æ˜¯", "ç„¶å¾Œ", "é‚„æœ‰", "åªæ˜¯", "ç”šè‡³", "è€Œä¸”", "ä¸å¦‚", "å¦‚æœ"
    ])
    if os.path.exists("stop_words.txt"):
        with open("stop_words.txt", "r", encoding="utf-8") as f:
            for line in f: stop_words.add(line.strip())

    def get_kw_df(texts):
        full = " ".join([str(t) for t in texts])
        tags = jieba.analyse.extract_tags(full, topK=80, withWeight=True)
        filtered = [(w, s) for w, s in tags if w not in stop_words and len(w)>1 and not w.isdigit()]
        return pd.DataFrame(filtered[:8], columns=['é—œéµè©', 'æ¬Šé‡'])

    with c_neg:
        st.markdown("#### ğŸ˜¡ è² é¢ç—›é»")
        if not neg_df.empty:
            kw_neg = get_kw_df(neg_df['content'].tolist())
            if not kw_neg.empty:
                st.plotly_chart(plot_clean_bar(kw_neg, '#d63031'), use_container_width=True)
            with st.expander("æŸ¥çœ‹è² è©•åˆ—è¡¨"):
                st.dataframe(neg_df[['date','source','content']], hide_index=True)
        else: st.info("ç„¡æ•¸æ“š")

    with c_pos:
        st.markdown("#### ğŸ¥° æ­£é¢äº®é»")
        if not pos_df.empty:
            kw_pos = get_kw_df(pos_df['content'].tolist())
            if not kw_pos.empty:
                st.plotly_chart(plot_clean_bar(kw_pos, '#00b894'), use_container_width=True)
            with st.expander("æŸ¥çœ‹å¥½è©•åˆ—è¡¨"):
                st.dataframe(pos_df[['date','source','content']], hide_index=True)
        else: st.info("ç„¡æ•¸æ“š")

st.markdown("---")
st.caption(f"System v15.0 (Rule-Based Restoration) | Updated: {datetime.now().strftime('%Y-%m-%d %H:%M')}")